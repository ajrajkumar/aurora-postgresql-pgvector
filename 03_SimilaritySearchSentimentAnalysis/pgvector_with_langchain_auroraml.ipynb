{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Search and Aurora Machine Learning using pgvector and Amazon Aurora PostgreSQL\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "1. Use HuggingFace's sentence transformer model [all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) and PostgreSQL extension [pgvector](https://github.com/pgvector/pgvector) to perform similarity search on a fictitious hotel reviews dataset. \n",
    "2. Perform Sentiment Analysis using [Amazon Aurora Machine Learning](https://aws.amazon.com/rds/aurora/machine-learning/).\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [pgvector](#Open-source-extension-pgvector-for-PostgreSQL)\n",
    "1. [Load test data](#Load-test-data)\n",
    "1. [Split text into chunks](#Split-text-into-chunks)\n",
    "1. [Create collection](#Create-collection)\n",
    "1. [Calculate cosine similarity](#Calculate-cosine-similarity)\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "Amazon Comprehend is a natural language processing (NLP) service that uses machine learning to find insights and relationships in text. No prior machine learning experience is required. This example will walk you through the process of integrating Aurora with the Comprehend Sentiment Analysis API and making sentiment analysis inferences via SQL commands. For our example, we have used a sample dataset for fictitious hotel reviews. We use a pretrained SentenceTransformer model `all-mpnet-base-v2` from [HuggingFace Transformers](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) for generating vector embeddings and store vector embeddings in our Aurora PostgreSQL DB cluster with pgvector. The sentiment analysis part of this demo will be done via psql, a popular PostgreSQL client in a hosted AWS Cloud9 terminal environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "Install required python libraries for the setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements1.txt\n",
    "!pip install -r requirements2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open-source extension pgvector for PostgreSQL\n",
    "\n",
    "[pgvector](https://github.com/pgvector/pgvector) is an open-source extension for PostgreSQL that allows you to store and search vector embeddings for exact and approximate nearest neighbors. It is designed to work seamlessly with other PostgreSQL features, including indexing and querying.\n",
    "\n",
    "PGVector integration with LangChain needs the connection string to the database. In this step, we generate the embeddings we as well as setup the connection string. Note that we pass in the connection string as well as the HuggingFace API Token from our `.env` file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain.docstore.document import Document\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'false'\n",
    "\n",
    "embeddings = HuggingFaceInstructEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Create the connection string for pgvector. Ref: https://github.com/langchain-ai/langchain-postgres/blob/main/examples/vectorstore.ipynb\n",
    "db_user = os.getenv('PGVECTOR_USER')\n",
    "db_password = os.getenv('PGVECTOR_PASSWORD')\n",
    "db_host = os.getenv('PGVECTOR_HOST')\n",
    "db_port = os.getenv('PGVECTOR_PORT')\n",
    "db_name = os.getenv('PGVECTOR_DATABASE')\n",
    "connection = f\"postgresql+psycopg://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "\n",
    "vectorstore = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    connection=connection,\n",
    "    use_jsonb=True                   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data\n",
    "\n",
    "Load our sample fictitious hotel dataset (CSV) with LangChain's [CSVLoader](https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader('./data/fictitious_hotel_reviews_trimmed_500.csv')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split text into chunks\n",
    "\n",
    "Split the text using LangChainâ€™s [CharacterTextSplitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/character_text_splitter) function and generate chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "print(len(docs))\n",
    "\n",
    "# Access the content and metadata of each document\n",
    "for document in documents:\n",
    "    content = print(document.page_content)\n",
    "    metadata = print(document.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create collection\n",
    "\n",
    "The PGVector module will try to create a table with the name of the collection. So, make sure that the collection name is unique and the user has the permission to create a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "collection_name = \"fictitious_hotel_reviews\"\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "     embedding=embeddings,\n",
    "     documents=docs,\n",
    "     collection_name=collection_name,\n",
    "     connection=connection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity search with score\n",
    "\n",
    "Run a similarity search using the [similarity_search_with_score](https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/pgvector) function from pgvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What do some of the positive reviews say?\"\n",
    "docs_with_score: List[Tuple[Document, float]] = db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate cosine similarity\n",
    "\n",
    "Use the Cosine function to refine the results to the best possible match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_postgres.vectorstores import DistanceStrategy\n",
    "\n",
    "store = PGVector(\n",
    "    connection=connection,\n",
    "    embeddings=embeddings, \n",
    "    collection_name=\"fictitious_hotel_reviews\",\n",
    "    distance_strategy=DistanceStrategy.COSINE\n",
    ")\n",
    "\n",
    "retriever = store.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(input='What do some of the positive reviews say?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
