{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "694c13ad-ac66-4049-92bd-dbd08d107596",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Module 1\n",
    "\n",
    "### Part-1 TSNE to visualize vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a333939f",
   "metadata": {},
   "source": [
    "In this section of the notebook, we will generate embeddings for sample text and plot them in a two-dimensional vector space. The purpose is to demonstrate how relationships between data points are measured through their distances from one another. We will use the t-SNE (t-Distributed Stochastic Neighbor Embedding) library to visualize these vectors. The final output will be displayed as a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110bf9d",
   "metadata": {},
   "source": [
    "In next cell, we will define a function to generate embeddings using the amazon.titan-embed-text-v2:0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\")\n",
    "embeddings_model_id = 'amazon.titan-embed-text-v2:0'\n",
    "\n",
    "\n",
    "def generate_embeddings(model_id, body):\n",
    "    \"\"\"\n",
    "    Generate a vector of embeddings for a text input using Amazon Titan Text Embeddings v2 on demand.\n",
    "    Args:\n",
    "        model_id (str): The model ID to use.\n",
    "        body (str) : The request body to use.\n",
    "    Returns:\n",
    "        response (JSON): The embedding created by the model and the number of input tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, modelId=model_id, accept=accept, contentType=content_type\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb3643e",
   "metadata": {},
   "source": [
    "In the next cell we will define a function to create pandas DataFrame from a list of text strings. Creating a DataFrame from text data is a common step in natural language processing tasks, as it allows you to easily manipulate and analyze the text data using pandas' powerful data manipulation and analysis capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce7c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_embeddings_df(texts):\n",
    "    df = pd.DataFrame(texts, columns=[\"text\"])\n",
    "    df[\"embedding\"] = df[\"text\"].apply(lambda text: generate_embeddings(embeddings_model_id, json.dumps\n",
    "    ({\"inputText\": text, \"dimensions\": 1024, \"normalize\": True})).get('embedding'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dda9e06",
   "metadata": {},
   "source": [
    "In the next cell, we will pass an array of texts to generate embeddings. Here, we will display each text and its corresponding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f2af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for learning the concepts\n",
    "texts = [\n",
    "    \"Red\",\n",
    "    \"White\",\n",
    "    \"Blue\",\n",
    "    \"Fish\",\n",
    "    \"Horse\",\n",
    "    \"Cat\",\n",
    "    \"Orange\",\n",
    "    \"USA\",\n",
    "    \"Canada\",\n",
    "    \"Japan\"\n",
    "]\n",
    "\n",
    "# Call utility function to generate the embeddings\n",
    "df = get_embeddings_df(texts)\n",
    "\n",
    "# Show the embeddings\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e3c07",
   "metadata": {},
   "source": [
    "In the next cell, we will use tSNE (t-Distributed Stochastic Neighbor Embedding) is a popular technique for dimensionality reduction and visualization of high-dimensional data. It is particularly useful for visualizing embeddings or vectors in a lower-dimensional space, typically 2D or 3D, which can be easily plotted and interpreted. Let's see how our data looks in a two-dimensional vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26380221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_tsne_plot(df):\n",
    "    embeddings = np.array(df[\"embedding\"].tolist())\n",
    "\n",
    "    tsne = TSNE(n_components=2, learning_rate=\"auto\", init=\"random\", random_state=4, perplexity=3)\n",
    "    embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=\"blue\", alpha=0.6, label=\"Embeddings\")\n",
    "\n",
    "    for i, txt in enumerate(df[\"text\"]):\n",
    "        plt.annotate(\n",
    "            txt, (embeddings_2d[i, 0], embeddings_2d[i, 1]), textcoords=\"offset points\", xytext=(0, 5), ha=\"center\"\n",
    "        )\n",
    "\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "    # lines\n",
    "    for i in range(len(embeddings_2d)):\n",
    "        for j in range(i+1, len(embeddings_2d)):  # avoid repeating the same pair\n",
    "            sim = similarity_matrix[i, j]\n",
    "            # higher similarity = bolder lines\n",
    "            alpha = sim \n",
    "            if sim > 0:  # plot lines for positive similarity values\n",
    "                plt.plot(\n",
    "                    [embeddings_2d[i, 0], embeddings_2d[j, 0]],\n",
    "                    [embeddings_2d[i, 1], embeddings_2d[j, 1]],\n",
    "                    color='gray', linestyle='-', alpha=alpha, linewidth=2*sim\n",
    "                )\n",
    "\n",
    "    plt.title(\"2D Visualization of Text Embeddings using t-SNE with Cosine Similarity\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3987807",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tsne_plot(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
